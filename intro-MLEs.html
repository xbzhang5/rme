<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Regression Models for Epidemiology - Appendix C — Introduction to Maximum Likelihood Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./common-mistakes.html" rel="next">
<link href="./estimation.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-W625DGE908"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-W625DGE908', { 'anonymize_ip': true});
</script><script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false,
  "enableExperimentalNewNoteButton": true
}
</script><script async="" src="https://hypothes.is/embed.js"></script><script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script><link href="site_libs/table1-1.0/table1_defaults.css" rel="stylesheet">
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="custom.scss">
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./probability.html">Appendices</a></li><li class="breadcrumb-item"><a href="./intro-MLEs.html"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Introduction to Maximum Likelihood Inference</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Regression Models for Epidemiology</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/d-morrison/rme" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Regression-Models-for-Epidemiology.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro-to-GLMs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./glms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Generalized Linear Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Linear-models-overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear (Gaussian) Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Models for Binary Outcomes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./count-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Models for Count Outcomes</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./time-to-event-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Time to Event Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro-to-survival-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./proportional-hazards-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Proportional Hazards Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./coxph-model-building.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Building Cox Proportional Hazards models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./parametric-survival-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Parametric survival models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro-MLEs.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Introduction to Maximum Likelihood Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./common-mistakes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Common Mistakes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Notation</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">C.1</span> Introduction</a></li>
  <li><a href="#example-maximum-likelihood-for-tropical-cyclones-in-australia" id="toc-example-maximum-likelihood-for-tropical-cyclones-in-australia" class="nav-link" data-scroll-target="#example-maximum-likelihood-for-tropical-cyclones-in-australia"><span class="header-section-number">C.2</span> Example: Maximum likelihood for Tropical Cyclones in Australia</a></li>
  <li>
<a href="#maximum-likelihood-inference-for-univariate-gaussian-models" id="toc-maximum-likelihood-inference-for-univariate-gaussian-models" class="nav-link" data-scroll-target="#maximum-likelihood-inference-for-univariate-gaussian-models"><span class="header-section-number">C.3</span> Maximum likelihood inference for univariate Gaussian models</a>
  <ul class="collapse">
<li><a href="#mle-of-mu" id="toc-mle-of-mu" class="nav-link" data-scroll-target="#mle-of-mu"><span class="header-section-number">C.3.1</span> MLE of <span class="math inline">\(\mu\)</span></a></li>
  <li><a href="#mle-of-sigma2" id="toc-mle-of-sigma2" class="nav-link" data-scroll-target="#mle-of-sigma2"><span class="header-section-number">C.3.2</span> MLE of <span class="math inline">\(\sigma^{2}\)</span></a></li>
  <li><a href="#covariance-matrix-of-mles" id="toc-covariance-matrix-of-mles" class="nav-link" data-scroll-target="#covariance-matrix-of-mles"><span class="header-section-number">C.3.3</span> Covariance matrix of MLEs</a></li>
  <li><a href="#confidence-intervals-for-mles" id="toc-confidence-intervals-for-mles" class="nav-link" data-scroll-target="#confidence-intervals-for-mles"><span class="header-section-number">C.3.4</span> Confidence intervals for MLEs</a></li>
  <li><a href="#p-values-and-hypothesis-tests-for-mles" id="toc-p-values-and-hypothesis-tests-for-mles" class="nav-link" data-scroll-target="#p-values-and-hypothesis-tests-for-mles"><span class="header-section-number">C.3.5</span> p-values and hypothesis tests for MLEs</a></li>
  <li><a href="#likelihood-ratio-tests-for-mles" id="toc-likelihood-ratio-tests-for-mles" class="nav-link" data-scroll-target="#likelihood-ratio-tests-for-mles"><span class="header-section-number">C.3.6</span> Likelihood ratio tests for MLEs</a></li>
  <li><a href="#prediction-intervals-for-mles" id="toc-prediction-intervals-for-mles" class="nav-link" data-scroll-target="#prediction-intervals-for-mles"><span class="header-section-number">C.3.7</span> Prediction intervals for MLEs</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/d-morrison/rme/edit/main/intro-MLEs.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/d-morrison/rme/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./probability.html">Appendices</a></li><li class="breadcrumb-item"><a href="./intro-MLEs.html"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Introduction to Maximum Likelihood Inference</span></a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Appendix C — Introduction to Maximum Likelihood Inference</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">Last modified: 2024-04-18: 11:51:26 (AM)</p>
    </div>
  </div>
  
    
  </div>
  


</header><p>These notes are derived primarily from <span class="citation" data-cites="dobson2018introduction">Dobson and Barnett (<a href="references.html#ref-dobson2018introduction" role="doc-biblioref">2018</a>)</span> (mostly chapters 1-5).</p>
<p>Some material was also taken from <span class="citation" data-cites="mclachlan2007algorithm">McLachlan and Krishnan (<a href="references.html#ref-mclachlan2007algorithm" role="doc-biblioref">2007</a>)</span> and <span class="citation" data-cites="CaseBerg01">Casella and Berger (<a href="references.html#ref-CaseBerg01" role="doc-biblioref">2002</a>)</span>.</p>
<section id="introduction" class="level2" data-number="C.1"><h2 data-number="C.1" class="anchored" data-anchor-id="introduction">
<span class="header-section-number">C.1</span> Introduction</h2>
<div id="def-lik" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.1 (Likelihood)</strong></span> Let <span class="math inline">\(\tilde{x}\)</span> be a dataset with corresponding random variable <span class="math inline">\(\tilde{X}\)</span>. Let <span class="math inline">\(p_\Theta(\tilde{X})\)</span> be a probability model for the distribution of <span class="math inline">\(\tilde{X}\)</span> with parameter vector <span class="math inline">\(\Theta\)</span>.</p>
<p>Then the <strong>likelihood</strong> of parameter value <span class="math inline">\(\theta\)</span> (for model <span class="math inline">\(p_\Theta(\tilde{X})\)</span>) is the <em>joint probability</em> of <span class="math inline">\(\tilde{x}\)</span> given <span class="math inline">\(\Theta = \theta\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\mathcal{L}(\theta) &amp;\stackrel{\text{def}}{=}p_{\theta}(\tilde{X})
\\&amp;=p_{\theta}(X_1=x_1, ..., X_n = x_n)
\end{aligned}
\]</span></p>
</div>
<p>The likelihood is a function that takes <span class="math inline">\(\theta\)</span> (and implicitly, <span class="math inline">\(\tilde{X}\)</span>) as inputs and outputs a single number, the joint probability of <span class="math inline">\(\tilde{X}\)</span> for model <span class="math inline">\(p_\Theta(\tilde{X})\)</span> with <span class="math inline">\(\Theta = \theta\)</span>.</p>
<div id="def-mle" class="theorem definition">
<p><span class="theorem-title"><strong>Definition C.2 (Maximum likelihood estimate)</strong></span> The <strong>maximum likelihood estimate</strong> of a parameter vector <span class="math inline">\(\theta\)</span> is the value of <span class="math inline">\(\theta\)</span> that maximizes the likelihood:</p>
<p><span class="math display">\[
\hat\theta_{\text{ML}}= \arg \max_\theta \mathcal{L}(\theta)
\]</span></p>
</div>
</section><section id="example-maximum-likelihood-for-tropical-cyclones-in-australia" class="level2" data-number="C.2"><h2 data-number="C.2" class="anchored" data-anchor-id="example-maximum-likelihood-for-tropical-cyclones-in-australia">
<span class="header-section-number">C.2</span> Example: Maximum likelihood for Tropical Cyclones in Australia</h2>
<p>The <code>cyclones</code> dataset in the <code>dobson</code> package (<a href="#tbl-cyclones-data" class="quarto-xref">Table&nbsp;<span>C.1</span></a>) records the number of tropical cyclones in Northeastern Australia during 13 November-to-April cyclone seasons (more details in <span class="citation" data-cites="dobson2018introduction">Dobson and Barnett (<a href="references.html#ref-dobson2018introduction" role="doc-biblioref">2018</a>)</span> §1.6.5 and <code><a href="https://rdrr.io/pkg/dobson/man/cyclones.html">help(cyclones, package = "dobson")</a></code>). <a href="#fig-dobson-cyclone-time-series" class="quarto-xref">Figure&nbsp;<span>C.1</span></a> graphs the number of cyclones (y-axis) by season (x-axis). Let’s use <span class="math inline">\(Y_i\)</span> to represent these counts, where <span class="math inline">\(i\)</span> is an indexing variable for the seasons and <span class="math inline">\(Y_i\)</span> is the number of cyclones in season <span class="math inline">\(i\)</span>.</p>
<p>Suppose we want to learn about how many cyclones to expect per season.</p>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">dobson</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rapporter.github.io/pander/">pander</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/pander/man/pander.html">pander</a></span><span class="op">(</span><span class="va">cyclones</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/relocate.html">relocate</a></span><span class="op">(</span><span class="va">season</span>, .before <span class="op">=</span> <span class="fu"><a href="https://tidyselect.r-lib.org/reference/everything.html">everything</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div id="tbl-cyclones-data" class="cell quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-cyclones-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;C.1: Number of tropical cyclones during a season from November to April in Northeastern Australia
</figcaption><div aria-describedby="tbl-cyclones-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell table table-sm table-striped small">
<colgroup>
<col style="width: 12%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;">season</th>
<th style="text-align: center;">years</th>
<th style="text-align: center;">number</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1956/7</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">1957/8</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">1958/9</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">1959/60</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">1960/1</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">1961/2</td>
<td style="text-align: center;">3</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">1962/3</td>
<td style="text-align: center;">12</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">1963/4</td>
<td style="text-align: center;">7</td>
</tr>
<tr class="odd">
<td style="text-align: center;">9</td>
<td style="text-align: center;">1964/5</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;">10</td>
<td style="text-align: center;">1965/6</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="odd">
<td style="text-align: center;">11</td>
<td style="text-align: center;">1966/7</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">12</td>
<td style="text-align: center;">1967/8</td>
<td style="text-align: center;">7</td>
</tr>
<tr class="odd">
<td style="text-align: center;">13</td>
<td style="text-align: center;">1968/9</td>
<td style="text-align: center;">4</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="va">cyclones</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>years <span class="op">=</span> <span class="va">years</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span>level <span class="op">=</span> <span class="va">years</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">years</span>, </span>
<span>        y <span class="op">=</span> <span class="va">number</span>,</span>
<span>        group <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Season"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Number of cyclones"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/expand_limits.html">expand_limits</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>vjust <span class="op">=</span> <span class="fl">.5</span>, angle <span class="op">=</span> <span class="fl">45</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-dobson-cyclone-time-series" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-dobson-cyclone-time-series-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.1: Number of tropical cyclones per season in northeastern Australia, 1956-1969
</figcaption><div aria-describedby="fig-dobson-cyclone-time-series-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="intro-MLEs_files/figure-html/fig-dobson-cyclone-time-series-1.png" class="img-fluid figure-img" width="672">
</div>
</figure>
</div>
</div>
</div>
<p>There’s no obvious correlation between adjacent seasons, so let’s assume that each season is independent of the others.</p>
<p>Let’s also assume that they are identically distributed; let’s denote this distribution as <span class="math inline">\(P(Y=y)\)</span> (note that there’s no index <span class="math inline">\(i\)</span> in this expression, since we are assuming the <span class="math inline">\(Y_i\)</span>s are identically distributed). We can visualize the distribution using a bar plot (<a href="#fig-cyclones-bar-plot" class="quarto-xref">Figure&nbsp;<span>C.2</span></a>). <a href="#tbl-dobson-cyclones-sumstat" class="quarto-xref">Table&nbsp;<span>C.2</span></a> provides summary statistics.</p>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cyclones</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">number</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/expand_limits.html">expand_limits</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Number of cyclones"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Count (number of seasons)"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-cyclones-bar-plot" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-cyclones-bar-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.2: Bar plot of cyclones per season
</figcaption><div aria-describedby="fig-cyclones-bar-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="intro-MLEs_files/figure-html/fig-cyclones-bar-plot-1.png" class="img-fluid figure-img" width="672">
</div>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cyclones</span> <span class="op">|&gt;</span> <span class="fu">table1</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/table1/man/table1.html">table1</a></span><span class="op">(</span>x <span class="op">=</span> <span class="op">~</span> <span class="va">number</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div id="tbl-dobson-cyclones-sumstat" class="cell quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-dobson-cyclones-sumstat-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;C.2: Summary statistics for <code>cyclones</code> data
</figcaption><div aria-describedby="tbl-dobson-cyclones-sumstat-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div>
<div class="Rtable1">
<table class="Rtable1 do-not-create-environment cell table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead><tr class="header">
<th class="rowlabel firstrow lastrow" data-quarto-table-cell-role="th"></th>
<th class="firstrow lastrow" data-quarto-table-cell-role="th"><span class="stratlabel">Overall<br><span class="stratn">(N=13)</span></span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td class="rowlabel firstrow">number</td>
<td class="firstrow"></td>
</tr>
<tr class="even">
<td class="rowlabel">Mean (SD)</td>
<td>5.54 (2.47)</td>
</tr>
<tr class="odd">
<td class="rowlabel lastrow">Median [Min, Max]</td>
<td class="lastrow">6.00 [2.00, 12.0]</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>We want to estimate <span class="math inline">\(P(Y=y)\)</span>; that is, <span class="math inline">\(P(Y=y)\)</span> is our <a href="#estimation.qmd#def-estimand">estimand</a>.</p>
<p>We could estimate <span class="math inline">\(P(Y=y)\)</span> for each value of <span class="math inline">\(y\)</span> in <span class="math inline">\(0:\infty\)</span> separately (“nonparametrically”) using the fraction of our data with <span class="math inline">\(Y_i=y\)</span>, but then we would be estimating an infinitely large set of parameters, and we would have low precision. We will probably do better with a parametric model.</p>
<div id="exr-cyclone-choose-dist" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.1</strong></span> What parametric probability distribution family might we use to model this empirical distribution?</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span>Let’s use the Poisson. The Poisson distribution is appropriate for this data , because the data are counts that could theoretically take any integer value (discrete) in the range <span class="math inline">\(0:\infty\)</span>. Visually, the plot of our data closely resembles a Poisson or binomial distribution. Since cyclones do not have an “upper limit” on the number of events we could potentially observe in one season, the Poisson distribution is more appropriate than the binomial.</p>
</div>
</div>
<div id="exr-def-poisson" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.2</strong></span> Write down the Poisson distribution’s probability mass function.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span><span class="math display">\[P(Y=y) = \frac{\lambda^{y} e^{-\lambda}}{y!}\]</span></p>
</div>
</div>
<p>Now, we can estimate the parameter <span class="math inline">\(\lambda\)</span> for this distribution using maximum likelihood estimation.</p>
<p>What is the likelihood?</p>
<div id="exr-poisson-likelihood" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.3</strong></span> Write down the likelihood (probability mass function or probability density function) of a single observation <span class="math inline">\(x\)</span>, according to your model.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span><span class="math display">\[
\begin{aligned}
\mathcal{L}(\lambda; x)
&amp;= p(X=x|\Lambda = \lambda)\\
&amp;= \frac{\lambda^x e^{-\lambda}}{x!}\\
\end{aligned}
\]</span></p>
</div>
</div>
<div id="exr-poisson-parameters" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.4</strong></span> Write down the vector of parameters in your model.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span>There is only one parameter, <span class="math inline">\(\lambda\)</span>:</p>
<p><span class="math display">\[\theta = (\lambda)\]</span></p>
</div>
</div>
<div id="exr-poisson-mean-and-variance" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.5</strong></span> Write down the population mean and variance of a single observation from your chosen probability model, as a function of the parameters (extra credit - derive them).</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span></p>
<ul>
<li>Population mean: <span class="math inline">\(\text{E}[X]=\lambda\)</span>
</li>
<li>Population variance: <span class="math inline">\(\text{Var}(X)=\lambda\)</span>
</li>
</ul>
</div>
</div>
<div id="exr-sample-likelihood" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.6</strong></span> Write down the likelihood of the full dataset.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span><span class="math display">\[
\begin{aligned}
\mathcal{L}(\lambda; \tilde x)
&amp;= P(\tilde X = \tilde x) \\
&amp;= P(X_1 = x_1, X_2 = x_2, ..., X_{13} = x_{13}) \\
&amp;= \prod_{i=1}^{13} P(X_i = x_i) \\
&amp;= \prod_{i=1}^{13} \frac{\lambda^{x_i} e^{-\lambda}}{x_i!}
\end{aligned}
\]</span></p>
</div>
</div>
<div id="exr-graph-likelihood" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.7</strong></span> Graph the likelihood as a function of <span class="math inline">\(\lambda\)</span>.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span></p>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lik</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">lambda</span>, <span class="va">y</span> <span class="op">=</span> <span class="va">cyclones</span><span class="op">$</span><span class="va">number</span>, <span class="va">n</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="op">{</span></span>
<span>  <span class="va">lambda</span><span class="op">^</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">n</span><span class="op">*</span><span class="va">lambda</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html">geom_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="va">lik</span>, n <span class="op">=</span> <span class="fl">1001</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">$</span><span class="va">number</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">$</span><span class="va">number</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"likelihood"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">'lambda'</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-cyclone-lik" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-cyclone-lik-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.3: Likelihood of Dobson cyclone data
</figcaption><div aria-describedby="fig-cyclone-lik-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="intro-MLEs_files/figure-html/fig-cyclone-lik-1.png" class="img-fluid figure-img" width="672">
</div>
</figure>
</div>
</div>
</div>
</div>
</div>
<div id="exr-sample-llik" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.8</strong></span> Write down the log-likelihood of the full dataset.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span><span class="math display">\[
\begin{aligned}
\ell(\lambda; \tilde{x}) &amp;= \text{log}\left\{\mathcal{L}(\lambda;\tilde{x})\right\}\\
&amp;= \text{log}\left\{\prod_{i = 1}^n\frac{\lambda^{x_i}\text{e}^{-\lambda}}{x_i!}\right\}\\
&amp;= \sum_{i = 1}^n\text{log}\left\{\frac{\lambda^{x_i}\text{e}^{-\lambda}}{x_i!}\right\}\\
&amp;= \sum_{i = 1}^n{\text{log}\left\{\lambda^{x_i}\right\} +\text{log}\left\{\text{e}^{-\lambda}\right\} - \text{log}\left\{x_i!\right\}}\\
&amp;= \sum_{i = 1}^n{x_i\text{log}\left\{\lambda\right\} -\lambda - \text{log}\left\{x_i!\right\}}\\
&amp;= \sum_{i = 1}^nx_i\text{log}\left\{\lambda\right\} - \sum_{i = 1}^n\lambda - \sum_{i = 1}^n\text{log}\left\{x_i!\right\}\\
&amp;= \sum_{i = 1}^nx_i\text{log}\left\{\lambda\right\} - n\lambda - \sum_{i = 1}^n\text{log}\left\{x_i!\right\}\\
\end{aligned}
\]</span></p>
</div>
</div>
<div id="exr-graph-loglikelihood" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.9</strong></span> Graph the log-likelihood as a function of <span class="math inline">\(\lambda\)</span>.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span></p>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">loglik</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">lambda</span>, <span class="va">y</span> <span class="op">=</span> <span class="va">cyclones</span><span class="op">$</span><span class="va">number</span>, <span class="va">n</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span> <span class="op">-</span> <span class="va">n</span><span class="op">*</span><span class="va">lambda</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">ll_plot</span> <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html">geom_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="va">loglik</span>, n <span class="op">=</span> <span class="fl">1001</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">$</span><span class="va">number</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">$</span><span class="va">number</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"log-likelihood"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">'lambda'</span><span class="op">)</span></span>
<span><span class="va">ll_plot</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-cyclone-llik" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-cyclone-llik-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.4: log-likelihood of Dobson cyclone data
</figcaption><div aria-describedby="fig-cyclone-llik-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="intro-MLEs_files/figure-html/fig-cyclone-llik-1.png" class="img-fluid figure-img" width="672">
</div>
</figure>
</div>
</div>
</div>
</div>
</div>
<div id="exr-cyclone-score-fn" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.10</strong></span> Derive the score function for the dataset.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span>The score function is the first derivative(s) of the log-likelihood:</p>
<p><span class="math display">\[
\begin{aligned}
\ell'( \lambda; \tilde{x} ) &amp;=
\frac{\partial}{\partial\lambda}{\sum_{i = 1}^nx_i\text{log}\left\{\lambda\right\} - n\lambda - \sum_{i = 1}^n\text{log}\left\{x_i!\right\}}\\
&amp;= \frac{\partial}{\partial\lambda}\sum_{i = 1}^nx_i\text{log}\left\{\lambda\right\} - \frac{\partial}{\partial\lambda}n\lambda - \frac{\partial}{\partial\lambda}\sum_{i = 1}^n\text{log}\left\{x_i!\right\}\\
&amp;= \sum_{i = 1}^nx_i\frac{\partial}{\partial\lambda}\text{log}\left\{\lambda\right\} - n\frac{\partial}{\partial\lambda}\lambda - \sum_{i = 1}^n\frac{\partial}{\partial\lambda}\text{log}\left\{x_i!\right\}\\
&amp;= \sum_{i = 1}^nx_i\frac{1}{\lambda} - n - 0\\
&amp;= \frac{1}{\lambda} \sum_{i = 1}^nx_i- n
\end{aligned}
\]</span></p>
</div>
</div>
<div id="exr-graph-score-function" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.11</strong></span> Graph the score function.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span></p>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">score</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">lambda</span>, <span class="va">y</span> <span class="op">=</span> <span class="va">cyclones</span><span class="op">$</span><span class="va">number</span>, <span class="va">n</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">/</span><span class="va">lambda</span> <span class="op">-</span> <span class="va">n</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html">geom_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="va">score</span>, n <span class="op">=</span> <span class="fl">1001</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">$</span><span class="va">number</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">$</span><span class="va">number</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"log-likelihood"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">'lambda'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, col <span class="op">=</span> <span class="st">'red'</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-cyclone-score" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-cyclone-score-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.5: score function of Dobson cyclone data
</figcaption><div aria-describedby="fig-cyclone-score-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="intro-MLEs_files/figure-html/fig-cyclone-score-1.png" class="img-fluid figure-img" width="672">
</div>
</figure>
</div>
</div>
</div>
</div>
</div>
<div id="exr-hessian" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.12</strong></span> Derive the Hessian matrix.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span>The Hessian function for an iid sample is the 2nd derivative(s) of the log-likelihood:</p>
<p><span class="math display">\[
\begin{aligned}
\ell''( \lambda; \tilde{x} ) &amp;= \frac{\partial}{\partial\lambda}\left(\frac{1}{\lambda} \sum_{i = 1}^nx_i- n\right)\\
&amp;= \frac{\partial}{\partial\lambda}\frac{1}{\lambda} \sum_{i = 1}^nx_i- \frac{\partial}{\partial\lambda}n\\
&amp;= -\frac{1}{\lambda^2} \sum_{i = 1}^nx_i\\
&amp;= -\frac{1}{\lambda^2} n \bar x
\end{aligned}
\]</span></p>
</div>
</div>
<div id="exr-graph-hession" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.13</strong></span> Graph the Hessian.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span></p>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">hessian</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">lambda</span>, <span class="va">y</span> <span class="op">=</span> <span class="va">cyclones</span><span class="op">$</span><span class="va">number</span>, <span class="va">n</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">/</span><span class="va">lambda</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html">geom_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="va">hessian</span>, n <span class="op">=</span> <span class="fl">1001</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">$</span><span class="va">number</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">$</span><span class="va">number</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"log-likelihood"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">'lambda'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, col <span class="op">=</span> <span class="st">'red'</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-cyclone-hessian" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-cyclone-hessian-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.6: Hessian function of Dobson cyclone data
</figcaption><div aria-describedby="fig-cyclone-hessian-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="intro-MLEs_files/figure-html/fig-cyclone-hessian-1.png" class="img-fluid figure-img" width="672">
</div>
</figure>
</div>
</div>
</div>
</div>
</div>
<div id="exr-score-equation" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.14</strong></span> Write the score equation (estimating equation).</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span><span class="math display">\[\ell'( \lambda; \tilde{x} ) = 0\]</span></p>
</div>
</div>
<div id="exr-solve-score-equation" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.15</strong></span> Solve the estimating equation for <span class="math inline">\(\lambda\)</span>:</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span><span class="math display">\[
\begin{aligned}
0 &amp;= \frac{1}{\lambda}\sum_{i = 1}^nx_i - n\\
n &amp;= \frac{1}{\lambda}\sum_{i = 1}^nx_i\\
n\lambda &amp;= \sum_{i = 1}^nx_i\\
\lambda &amp;=
\frac{1}{n}\sum_{i = 1}^nx_i\\
&amp;=\bar x
\end{aligned}
\]</span></p>
</div>
</div>
<p>Let’s call this solution of the estimating equation <span class="math inline">\(\tilde \lambda\)</span> for now:</p>
<p><span class="math display">\[\tilde \lambda \stackrel{\text{def}}{=}\bar x\]</span></p>
<div id="exr-check-hessian" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.16</strong></span> Confirm that the Hessian <span class="math inline">\(\ell''(\lambda; \tilde{x})\)</span> is negative when evaluated at <span class="math inline">\(\tilde \lambda\)</span>.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span><span class="math display">\[
\begin{aligned}
\ell''( \tilde\lambda; \tilde{x} ) &amp;=
-\frac{1}{\tilde\lambda^2} n \bar x\\
&amp;= -\frac{1}{\bar x^2} n\bar x\\
&amp;= -\frac{n}{\bar x}\\
&amp;&lt;0\\
\end{aligned}
\]</span></p>
</div>
</div>
<div id="exr-find-mle" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.17</strong></span> Find the MLE of <span class="math inline">\(\lambda\)</span>.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span>Since <span class="math inline">\(\ell''(\tilde \lambda; \tilde{x})&lt;0\)</span>, <span class="math inline">\(\tilde \lambda\)</span> is at least a local maximizer of the likelihood function <span class="math inline">\(\mathcal L(\lambda)\)</span>. Since there is only one solution to the estimating equation and the Hessian is negative definite everywhere, <span class="math inline">\(\tilde \lambda\)</span> must also be the global maximizer of <span class="math inline">\(\mathcal L(\lambda; \tilde{x})\)</span>:</p>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mle</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">cyclones</span><span class="op">$</span><span class="va">number</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><span class="math display">\[\hat{\lambda}_{\text{ML}} = \bar x = 5.53846154\]</span></p>
</div>
</div>
<div id="exr-graph-mle" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise C.18</strong></span> Graph the log-likelihood with the MLE superimposed.</p>
<div class="proof solution">
<p><span class="proof-title"><em>Solution</em>. </span></p>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">mle_data</span> <span class="op">=</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">mle</span>, y <span class="op">=</span> <span class="fu">loglik</span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ll_plot</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">mle_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">'red'</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-cyclone-llik-mle" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-cyclone-llik-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;C.7: log-likelihood of Dobson cyclone data with MLE
</figcaption><div aria-describedby="fig-cyclone-llik-mle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="intro-MLEs_files/figure-html/fig-cyclone-llik-mle-1.png" class="img-fluid figure-img" width="672">
</div>
</figure>
</div>
</div>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold"><summary>Show R code</summary><div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">obs_inf</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">lambda</span>, <span class="va">y</span> <span class="op">=</span> <span class="va">cyclones</span><span class="op">$</span><span class="va">number</span>, <span class="va">n</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">/</span><span class="va">lambda</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="maximum-likelihood-inference-for-univariate-gaussian-models" class="level2" data-number="C.3"><h2 data-number="C.3" class="anchored" data-anchor-id="maximum-likelihood-inference-for-univariate-gaussian-models">
<span class="header-section-number">C.3</span> Maximum likelihood inference for univariate Gaussian models</h2>
<p>Suppose <span class="math inline">\(X_{1},\ldots,X_{n} \sim_{iid}N\left( \mu,\ \sigma^{2} \right)\)</span>. Let <span class="math inline">\(X = \left( X_{1},\ldots,X_{n} \right)^{\top}\)</span> be these random variables in vector format. Let <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(x\)</span> denote the corresponding observed data. Let <span class="math inline">\(\theta = \left( \mu,\sigma^{2} \right)^{\top}\)</span> be the vector of parameters. Let <span class="math inline">\(\Theta\)</span> denote the parameters as a random vector.</p>
<p>Then the log-likelihood <span class="math inline">\(\ell \stackrel{\text{def}}{=}\ell(X;\theta) \stackrel{\text{def}}{=}p\left( X = x \mid \Theta = \theta \right)\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
\ell
&amp;\propto - \frac{n}{2}\text{log}\left\{\sigma^{2}\right\} - \frac{1}{2}\sum_{i = 1}^{n}\frac{\left( x_{i} - \mu \right)^{2}}{\sigma^{2}}\\
&amp;= - \frac{n}{2}\text{log}\left\{\sigma^{2}\right\} - \frac{1}{2\sigma^{2}}\sum_{i = 1}^{n}{x_{i}^{2} - 2x_{i}\mu + \mu^{2}}
\end{aligned}
\]</span></p>
<section id="mle-of-mu" class="level3" data-number="C.3.1"><h3 data-number="C.3.1" class="anchored" data-anchor-id="mle-of-mu">
<span class="header-section-number">C.3.1</span> MLE of <span class="math inline">\(\mu\)</span>
</h3>
<p>Then:</p>
<p><span class="math display">\[\frac{d\ell}{d\mu} = - \frac{1}{2}\sum_{i = 1}^{n}\frac{- 2\left( x_{i} - \mu \right)}{\sigma^{2}}\]</span></p>
<p><span class="math display">\[= \frac{1}{\sigma^{2}}\left\lbrack \left( \sum_{i = 1}^{n}x_{i} \right) - n\mu \right\rbrack\]</span></p>
<p>If <span class="math inline">\(\frac{d\ell}{d\mu} = 0\)</span>, then <span class="math inline">\(\mu = \overline{x} \stackrel{\text{def}}{=}\frac{1}{n}\sum_{i = 1}^{n}x_{i}\)</span>.</p>
<p><span class="math display">\[\frac{d^{2}\ell}{(d\mu)^{2}} = \frac{- n}{\sigma^{2}} &lt; 0\]</span></p>
<p>So <span class="math inline">\({\widehat{\mu}}_{ML} = \overline{x}\)</span>.</p>
</section><section id="mle-of-sigma2" class="level3" data-number="C.3.2"><h3 data-number="C.3.2" class="anchored" data-anchor-id="mle-of-sigma2">
<span class="header-section-number">C.3.2</span> MLE of <span class="math inline">\(\sigma^{2}\)</span>
</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Reparametrizing the Gaussian distribution
</div>
</div>
<div class="callout-body-container callout-body">
<p>When solving for <span class="math inline">\({\widehat{\sigma}}_{ML}\)</span>, you can treat <span class="math inline">\(\sigma^{2}\)</span> as an atomic variable (don’t differentiate with respect to <span class="math inline">\(\sigma\)</span> or things get messy). In fact, you can replace <span class="math inline">\(\sigma^{2}\)</span> with <span class="math inline">\(1/\tau\)</span> and differentiate with respect to <span class="math inline">\(\tau\)</span> instead, and the process might be even easier.</p>
</div>
</div>
<p><span class="math display">\[\frac{d\ell}{d\sigma^{2}} = \frac{d}{d\sigma^{2}}\left( - \frac{n}{2}\text{log}\left\{\sigma^{2}\right\} - \frac{1}{2}\sum_{i = 1}^{n}\frac{\left( x_{i} - \mu \right)^{2}}{\sigma^{2}} \right)\ \]</span></p>
<p><span class="math display">\[= - \frac{n}{2}\left( \sigma^{2} \right)^{- 1} + \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2}\]</span></p>
<p>If <span class="math inline">\(\frac{d\ell}{d\sigma^{2}} = 0\)</span>, then:</p>
<p><span class="math display">\[\frac{n}{2}\left( \sigma^{2} \right)^{- 1} = \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2}\]</span></p>
<p><span class="math display">\[\sigma^{2} = \frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2}\]</span></p>
<p>We plug in <span class="math inline">\({\widehat{\mu}}_{ML} = \overline{x}\)</span> to maximize globally (a technique called profiling):</p>
<p><span class="math display">\[\sigma_{ML}^{2} = \frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}\]</span></p>
<p>Now:</p>
<p><span class="math display">\[
\begin{aligned}
\frac{d^{2}\ell}{\left( d\sigma^{2} \right)^{2}}
&amp;= \frac{d}{d\sigma^{2}}\left\{ - \frac{n}{2}\left( \sigma^{2} \right)^{- 1} + \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right\}\\
&amp;= \left\{ - \frac{n}{2}\frac{d}{d\sigma^{2}}\left( \sigma^{2} \right)^{- 1} + \frac{1}{2}\frac{d}{d\sigma^{2}}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right\}\\
&amp;= \left\{ \frac{n}{2}\left( \sigma^{2} \right)^{- 2} - \left( \sigma^{2} \right)^{- 3}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right\}\\
&amp;= \left( \sigma^{2} \right)^{- 2}\left\{ \frac{n}{2} - \left( \sigma^{2} \right)^{- 1}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right\}
\end{aligned}
\]</span></p>
<p>Evaluated at <span class="math inline">\(\mu = \overline{x},\sigma^{2} = \frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}\)</span>, we have:</p>
<p><span class="math display">\[
\begin{aligned}
\frac{d^{2}\ell}{\left( d\sigma^{2} \right)^{2}}
&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}\left\{ \frac{n}{2} - \left( {\widehat{\sigma}}^{2} \right)^{- 1}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2} \right\}\\
&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}\left\{ \frac{n}{2} - \left( {\widehat{\sigma}}^{2} \right)^{- 1}n{\widehat{\sigma}}^{2} \right\}\\
&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}\left\{ \frac{n}{2} - n \right\}\\
&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}n\left\{ \frac{1}{2} - 1 \right\}\\
&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}n\left( - \frac{1}{2} \right) &lt; 0
\end{aligned}
\]</span></p>
<p>Finally, we have:</p>
<p><span class="math display">\[
\begin{aligned}
\frac{d^{2}\ell}{d\mu\ d\sigma^{2}}
&amp;= \frac{d}{d\mu}\left\{ - \frac{n}{2}\left( \sigma^{2} \right)^{- 1} + \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right\}\\
&amp;= \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\frac{d}{d\mu}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2}\\
&amp;= \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}{- 2(x_{i} - \mu)}\\
&amp;= - \left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}{(x_{i} - \mu)}
\end{aligned}
\]</span></p>
<p>Evaluated at <span class="math inline">\(\mu = \widehat{\mu} = \overline{x},\sigma^{2} = {\widehat{\sigma}}^{2} = \frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}\)</span>, we have:</p>
<p><span class="math display">\[\frac{d^{2}\ell}{d\mu\ d\sigma^{2}} = - \left( {\widehat{\sigma}}^{2} \right)^{- 2}\left( n\overline{x} - n\overline{x} \right) = 0\]</span></p>
</section><section id="covariance-matrix-of-mles" class="level3" data-number="C.3.3"><h3 data-number="C.3.3" class="anchored" data-anchor-id="covariance-matrix-of-mles">
<span class="header-section-number">C.3.3</span> Covariance matrix of MLEs</h3>
<section id="the-score-function" class="level4"><h4 class="anchored" data-anchor-id="the-score-function">The score function</h4>
<p>Let <span class="math inline">\(\theta\)</span> be the vector of all parameters; here, <span class="math inline">\(\theta = \left( \mu,\sigma^{2} \right)^{\top}\)</span>.</p>
<p>Let <span class="math inline">\(\ell^{'}(x,\theta) \stackrel{\text{def}}{=}\frac{d}{d\theta}\ell(x,\theta) = \left( \begin{array}{r}
\frac{d}{d\mu}\ell(\theta;x) \\
\frac{d}{d\sigma^{2}}\ell(\theta;x)
\end{array} \right) = \left( \begin{array}{r}
\ell_{\mu}^{'}(\theta;x) \\
\ell_{\sigma^{2}}^{'}(\theta;x)
\end{array} \right)\)</span>.</p>
<p><span class="math inline">\(\ell^{'}(x,\theta)\)</span> is the function we set equal to 0 and solve to find the MLE:</p>
<p><span class="math display">\[{\widehat{\theta}}_{ML} = \left\{ \theta:\ell^{'}(x,\theta) = 0 \right\}\]</span></p>
<p>The function <span class="math inline">\(\ell^{'}(x,\theta)\)</span> is so central that it has its own name, the “score” or “gradient” function. Statisticians also often skip writing the arguments <span class="math inline">\((x,\theta)\)</span>, so <span class="math inline">\(\ell^{'} \stackrel{\text{def}}{=}\ell^{'}(x,\theta)\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Some statisticians use <span class="math inline">\(U\)</span> or <span class="math inline">\(S\)</span> instead of <span class="math inline">\(\ell^{'}\)</span>. I prefer <span class="math inline">\(\ell^{'}\)</span>. Why use up extra letters?</p>
</section><section id="the-fisher-expected-information-matrix" class="level4"><h4 class="anchored" data-anchor-id="the-fisher-expected-information-matrix">The (Fisher) (expected) information matrix</h4>
<p>The variance of <span class="math inline">\(\ell^{'}(x,\theta)\)</span>, <span class="math inline">\({Cov}\left\{ \ell^{'}(x,\theta) \right\}\)</span>, is also very important; we call it the “expected information matrix”, “Fisher information matrix”, or just “information matrix”, and we represent it using the symbol <span class="math inline">\(\mathfrak{I}\)</span> (<code>\frakturI</code> in Unicode, <code>\mathfrak{I}</code> in LaTeX).</p>
<section id="review-of-variances-and-covariances" class="level5"><h5 class="anchored" data-anchor-id="review-of-variances-and-covariances">Review of variances and covariances</h5>
<section id="variances-and-covariances-of-one-dimensional-random-variables" class="level6"><h6 class="anchored" data-anchor-id="variances-and-covariances-of-one-dimensional-random-variables">Variances and covariances of one-dimensional random variables</h6>
<p>For a one-dimensional random variables <span class="math inline">\(X\)</span>,</p>
<p><span class="math display">\[{Var}(X) \stackrel{\text{def}}{=}Ε\left\lbrack \left( X - Ε\lbrack X\rbrack \right)^{2} \right\rbrack = Ε\left\lbrack X^{2} \right\rbrack - \left( Ε\lbrack X\rbrack \right)^{2}\]</span></p>
<p>For any two-dimensional random variables, <span class="math inline">\(X,Y\)</span>:</p>
<p><span class="math display">\[{Cov}(X,Y) = E\left\lbrack (X - ΕX)(Y - ΕY) \right\rbrack = Ε\lbrack XY\rbrack - E\lbrack X\rbrack E\lbrack Y\rbrack\]</span></p>
<p>Therefore, <span class="math inline">\({Var}{(X)} = {Cov}(X,X) = Ε\lbrack XX\rbrack - E\lbrack X\rbrack E\lbrack X\rbrack = Ε\left\lbrack X^{2} \right\rbrack - \left( E\lbrack X\rbrack \right)^{2}\)</span></p>
<p><span class="math display">\[\mathfrak{I \stackrel{\text{def}}{=}I(}\theta) \stackrel{\text{def}}{=}{Cov}\left( \ell^{'}|\theta \right) = Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack - Ε\left\lbrack \ell^{'} \right\rbrack\ Ε\left\lbrack \ell^{'} \right\rbrack^{\top}\]</span></p>
<p>Sometimes we write <span class="math inline">\({Cov}{(X)} \stackrel{\text{def}}{=}{Cov}(X,X) = {Var}(X)\)</span>.</p>
</section><section id="variances-and-covariances-of-p-times-1-random-vectors" class="level6"><h6 class="anchored" data-anchor-id="variances-and-covariances-of-p-times-1-random-vectors">Variances and covariances of <span class="math inline">\(p \times 1\)</span> random vectors</h6>
<p>Now, for a <span class="math inline">\(p \times 1\)</span> dimensional random vector <span class="math inline">\(X\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\text{Var}(X)
&amp;\stackrel{\text{def}}{=}\text{Cov}(X)\\
&amp;\stackrel{\text{def}}{=}E\left\lbrack \left( X - E\lbrack X\rbrack \right)^{\top}\left( X - E\lbrack X\rbrack \right) \right\rbrack\\
&amp;= E\left\lbrack \left( X^{\top} - E\lbrack X\rbrack^{\top} \right)\left( X - E\lbrack X\rbrack \right) \right\rbrack\\
&amp;= E\left\lbrack X^{\top}X - E\lbrack X\rbrack^{\top}X - X^{\top}E\lbrack X\rbrack + E\lbrack X\rbrack^{\top}E\lbrack X\rbrack \right\rbrack\\
&amp;= E\left\lbrack X^{\top}X \right\rbrack - E\lbrack X\rbrack^{\top}E\lbrack X\rbrack - {E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack + E\lbrack X\rbrack^{\top}E\lbrack X\rbrack\\
&amp;= E\left\lbrack X^{\top}X \right\rbrack - 2{E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack + E\lbrack X\rbrack^{\top}E\lbrack X\rbrack\\
&amp;= E\left\lbrack X^{\top}X \right\rbrack - {E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack
\end{aligned}
\]</span></p>
<p>The elements of <span class="math inline">\(\mathfrak{I}\)</span> are:</p>
<p><span class="math display">\[\left\{ \mathfrak{I}_{ij} \stackrel{\text{def}}{=}{Cov}\left( {\ell^{'}}_{i},{\ell^{'}}_{j} \right) = Ε\left\lbrack \ell_{i}^{'}\ell_{j}^{'} \right\rbrack - Ε\left\lbrack {\ell^{'}}_{i} \right\rbrack Ε\left\lbrack {\ell^{'}}_{j} \right\rbrack \right\}\]</span></p>
<p>In our motivating example, <span class="math inline">\(i,j \in \left\{ \mu,\sigma^{2} \right\}\)</span>. Here,</p>
<p><span class="math display">\[
\begin{aligned}
Ε[\ell']
&amp;\stackrel{\text{def}}{=}\int_{x \in \mathfrak R(x)}{\ell'(x,\theta) p(X = x | \theta)dx}\\
&amp;= \int_{x\in \mathfrak R(x)}{\left( \frac{d}{d\theta}\text{log}\left\{p\left( X = x \mid \theta \right)\right\} \right)\ p\left( X = x \mid \theta \right)\ dx}\\
&amp;= \int_{x \in \mathfrak R(x)}{\frac{\frac{d}{d\theta}p\left( X = x \mid \theta \right)}{p\left( X = x \mid \theta \right)}p\left( X = x \mid \theta \right)\ dx
}\\
&amp;= \int_{x \in \mathfrak R(x)}{\frac{d}{d\theta}p\left( X = x \mid \theta \right)\ dx}
\end{aligned}
\]</span></p>
<p>And similarly</p>
<p><span class="math display">\[Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack \stackrel{\text{def}}{=}\int_{x \in R(x)}^{}{\ell^{'}(x,\theta)\ell^{'}(x,\theta)^{\top}\ p\left( X = x \mid \theta \right)\ dx}\]</span></p>
<p>Note that <span class="math inline">\(Ε\left\lbrack \ell^{'} \right\rbrack\)</span> and <span class="math inline">\(Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack\)</span> are functions of <span class="math inline">\(\theta\)</span> but not of <span class="math inline">\(x\)</span>; the expectation operator removed <span class="math inline">\(x\)</span>.</p>
<p>Also note that for most of the distributions you are familiar with (including Gaussian, binomial, Poisson, exponential),</p>
<p><span class="math display">\[Ε\left\lbrack \ell^{'} \right\rbrack = 0\]</span></p>
<p>So</p>
<p><span class="math display">\[\mathfrak{I =}Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack\]</span></p>
<p>Moreover, for those distributions (called the “exponential family”), we have:</p>
<p><span class="math display">\[\mathfrak{I = -}Ε\left\lbrack \ell^{''} \right\rbrack = Ε\left\lbrack - \ell^{''} \right\rbrack\]</span></p>
<p>(see Dobson and Barnett 4e, §3.17), where</p>
<p><span class="math display">\[\ell^{''} \stackrel{\text{def}}{=}\frac{d}{d\theta}\ell^{'(x,\theta)^{\top}} = \frac{d}{d\theta}\frac{d}{d\theta^{\top}}\ell(x,\theta)\]</span></p>
<p>is the <span class="math inline">\(p \times p\)</span> matrix whose elements are:</p>
<p><span class="math display">\[\ell_{ij}'' \stackrel{\text{def}}{=}\frac{d}{d\theta_{i}}\frac{d}{d\theta_{j}}\text{log}\left\{ p\left( X = x \mid \theta \right)\right\}\]</span></p>
<p><span class="math inline">\(\ell''\)</span> could be called the “Hessian” of the log-likelihood function.</p>
<p>Sometimes, we use <span class="math inline">\(I(\theta;x) \stackrel{\text{def}}{=}- \ell^{''}\)</span> (note the standard-font “I” here). <span class="math inline">\(I(\theta;x)\)</span> is the observed information, precision, or concentration matrix (Negative Hessian).</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key point
</div>
</div>
<div class="callout-body-container callout-body">
<p>The asymptotics of MLEs gives us <span class="math inline">\({\widehat{\theta}}_{ML} \sim N\left( \theta,\mathfrak{I}^{- 1}(\theta) \right)\)</span>, approximately, for large sample sizes.</p>
</div>
</div>
<p>We can estimate <span class="math inline">\(\mathfrak{I}^{- 1}(\theta)\)</span> by working out <span class="math inline">\(- Ε\left\lbrack \ell^{''} \right\rbrack\)</span> or <span class="math inline">\(Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack\)</span> and plugging in <span class="math inline">\({\widehat{\theta}}_{ML}\)</span>, but sometimes we instead use <span class="math inline">\(I\left( {\widehat{\theta}}_{ML};x \right)\)</span> for convenience; there are some cases where it’s provably better according to some criteria (Efron &amp; Hinkley 1978).</p>
<p>Note that later, when we are trying to find MLEs for likelihoods that we can’t easily differentiate, we will “hill-climb” using the Newton-Raphson algorithm:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\theta}
&amp;\leftarrow \widehat{\theta} + \left\lbrack I\left( \widehat{\theta},y \right) \right\rbrack^{- 1}\ell^{'}\left( y,\widehat{\theta} \right)\\
&amp;= \widehat{\theta} - \left\lbrack \ell^{''}\left( y,\widehat{\theta} \right) \right\rbrack^{- 1}\ell^{'}\left( y,\widehat{\theta} \right)
\end{aligned}
\]</span></p>
<p>Here, for computational simplicity, we will sometimes use <span class="math inline">\(\mathfrak{I}^{- 1}(\theta)\)</span> in place of <span class="math inline">\(I\left( \widehat{\theta},y \right)\)</span>; doing so is called “Fisher scoring” or the “method of scoring”. Note that this is the opposite of the substitution that we are making for estimating the variance of the MLE; this time we should technically use the observed information but we use the expected information instead.</p>
<p>There’s also an “empirical information matrix” (see McLachlan and Krishnan 2007).</p>
<p><span class="math display">\[I_{e}(\theta,y) = \sum_{i = 1}^{n}{\ell_{i}^{'}\ {\ell_{i}^{'}}^{\top}} - \frac{1}{n}\ell^{'}{\ell^{'}}^{\top}\]</span></p>
<p>where <span class="math inline">\(\ell_{i}\)</span> is the log-likelihood of the ith observation. Note that <span class="math inline">\(\ell^{'} = \sum_{i = 1}^{n}\ell_{i}^{'}\)</span>.</p>
<p><span class="math inline">\(\frac{1}{n}I_{e}(\theta,y)\)</span> is the sample equivalent of</p>
<p><span class="math display">\[\mathfrak{I \stackrel{\text{def}}{=}I(}\theta) \stackrel{\text{def}}{=}{Cov}\left( \ell^{'}|\theta \right) = Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack - Ε\left\lbrack \ell^{'} \right\rbrack\ Ε\left\lbrack \ell^{'} \right\rbrack^{\top}\]</span></p>
<p><span class="math display">\[\left\{ \mathfrak{I}_{jk} \stackrel{\text{def}}{=}{Cov}\left( {\ell^{'}}_{j},{\ell^{'}}_{k} \right) = Ε\left\lbrack \ell_{j}^{'}\ell_{k}^{'} \right\rbrack - Ε\left\lbrack {\ell^{'}}_{j} \right\rbrack Ε\left\lbrack {\ell^{'}}_{k} \right\rbrack \right\}\]</span></p>
<p><span class="math inline">\(I_{e}(\theta,y)\)</span> is sometimes computationally easier to compute for Newton-Raphson-type maximization algorithms.</p>
<p>Back to our Gaussian example:</p>
<p><span class="math display">\[I = \begin{bmatrix}
\frac{n}{\sigma^{2}} &amp; 0 \\
0 &amp; \left( {\widehat{\sigma}}^{2} \right)^{- 2}n\left( - \frac{1}{2} \right)
\end{bmatrix} = \begin{bmatrix}
a &amp; 0 \\
0 &amp; d
\end{bmatrix}\]</span></p>
<p>So:</p>
<p><span class="math display">\[I^{- 1} = \frac{1}{ad}\begin{bmatrix}
d &amp; 0 \\
0 &amp; a
\end{bmatrix} = \begin{bmatrix}
\frac{1}{a} &amp; 0 \\
0 &amp; \frac{1}{d}
\end{bmatrix}\]</span></p>
<p><span class="math display">\[I^{- 1} = \begin{bmatrix}
\frac{{\widehat{\sigma}}^{2}}{n} &amp; 0 \\
0 &amp; \frac{{2\left( {\widehat{\sigma}}^{2} \right)}^{2}}{n}
\end{bmatrix}\]</span></p>
<p>See <span class="citation" data-cites="CaseBerg01">Casella and Berger (<a href="references.html#ref-CaseBerg01" role="doc-biblioref">2002</a>)</span> p322, example 7.2.12.</p>
<p>To prove it’s a maximum, need:</p>
<ul>
<li><p><span class="math inline">\(\ell^{'} = 0\)</span></p></li>
<li><p>At least one diagonal element of <span class="math inline">\(\mathfrak{l''}\)</span> is negative.</p></li>
<li><p>Determinant of <span class="math inline">\(\mathfrak{l''}\)</span> is positive.</p></li>
</ul></section></section></section></section><section id="confidence-intervals-for-mles" class="level3" data-number="C.3.4"><h3 data-number="C.3.4" class="anchored" data-anchor-id="confidence-intervals-for-mles">
<span class="header-section-number">C.3.4</span> Confidence intervals for MLEs</h3>
</section><section id="p-values-and-hypothesis-tests-for-mles" class="level3" data-number="C.3.5"><h3 data-number="C.3.5" class="anchored" data-anchor-id="p-values-and-hypothesis-tests-for-mles">
<span class="header-section-number">C.3.5</span> p-values and hypothesis tests for MLEs</h3>
</section><section id="likelihood-ratio-tests-for-mles" class="level3" data-number="C.3.6"><h3 data-number="C.3.6" class="anchored" data-anchor-id="likelihood-ratio-tests-for-mles">
<span class="header-section-number">C.3.6</span> Likelihood ratio tests for MLEs</h3>
<p>[We haven’t gone over this yet]</p>
<p>log(likelihood ratio) tests <span class="citation" data-cites="dobson2018introduction">(c.f. <a href="references.html#ref-dobson2018introduction" role="doc-biblioref">Dobson and Barnett 2018, sec. 5.7</a>)</span>:</p>
<p><span class="math display">\[2\left( \mathfrak{l -}\ell_{0} \right) \sim \chi^{2}(p - q)\]</span></p>
<p>See also https://online.stat.psu.edu/stat504/book/export/html/657</p>
</section><section id="prediction-intervals-for-mles" class="level3" data-number="C.3.7"><h3 data-number="C.3.7" class="anchored" data-anchor-id="prediction-intervals-for-mles">
<span class="header-section-number">C.3.7</span> Prediction intervals for MLEs</h3>
<p><span class="math display">\[\overline{X} \in \left\lbrack \widehat{\mu} \pm z_{1 - \alpha\text{/}2}\frac{\sigma}{m} \right\rbrack\]</span></p>
<p>Where <span class="math inline">\(m\)</span> is the sample size of the new data to be predicted (typically 1, except for binary outcomes, where it needs to be bigger for prediction intervals to make sense)</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-CaseBerg01" class="csl-entry" role="listitem">
Casella, George, and Roger Berger. 2002. <em>Statistical Inference</em>. 2nd ed. Cengage Learning. <a href="https://www.cengage.com/c/statistical-inference-2e-casella-berger/9780534243128/">https://www.cengage.com/c/statistical-inference-2e-casella-berger/9780534243128/</a>.
</div>
<div id="ref-dobson2018introduction" class="csl-entry" role="listitem">
Dobson, Annette J, and Adrian G Barnett. 2018. <em>An Introduction to Generalized Linear Models</em>. 4th ed. CRC press. <a href="https://doi.org/10.1201/9781315182780">https://doi.org/10.1201/9781315182780</a>.
</div>
<div id="ref-mclachlan2007algorithm" class="csl-entry" role="listitem">
McLachlan, Geoffrey J, and Thriyambakam Krishnan. 2007. <em>The EM Algorithm and Extensions</em>. 2nd ed. John Wiley &amp; Sons. <a href="https://doi.org/10.1002/9780470191613">https://doi.org/10.1002/9780470191613</a>.
</div>
</div>
</section></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>I might sometimes switch the order of <span class="math inline">\(x,\)</span> <span class="math inline">\(\theta\)</span>; this is unintentional and not meaningful.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./estimation.html" class="pagination-link" aria-label="Estimation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Estimation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./common-mistakes.html" class="pagination-link" aria-label="Common Mistakes">
        <span class="nav-page-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Common Mistakes</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb12" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction to Maximum Likelihood Inference</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>{{&lt; include shared-config.qmd &gt;}}</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>These notes are derived primarily from @dobson2018introduction (mostly chapters 1-5).</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>Some material was also taken from @mclachlan2007algorithm and @CaseBerg01.</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>:::{#def-lik}</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Likelihood</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>Let $\vec x$ be a dataset with corresponding random variable $\vec X$.</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>Let $p_\Theta(\vec X)$ be a probability model for the distribution of $\vec X$ with parameter vector $\Theta$.</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>Then the **likelihood** of parameter value $\theta$ (for model $p_\Theta(\vec X)$) is the *joint probability* of $\vec x$ given $\Theta = \theta$:</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>\ba</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>\Lik(\theta) &amp;\eqdef p_{\theta}(\vec X)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="sc">\\</span>&amp;=p_{\theta}(X_1=x_1, ..., X_n = x_n)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>\ea</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>The likelihood is a function that takes $\theta$ (and implicitly, $\vec X$) as inputs and outputs a single number, the joint probability of $\vec X$ for model $p_\Theta(\vec X)$ with $\Theta = \theta$.</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>:::{#def-mle}</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Maximum likelihood estimate</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>The **maximum likelihood estimate** of a parameter vector $\theta$ is the value of $\theta$ that maximizes the likelihood:</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>\hthml = \arg \max_\theta \Lik(\theta)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>{{&lt; include dobson-cyclone-example.qmd &gt;}}</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a><span class="fu">## Maximum likelihood inference for univariate Gaussian models</span></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>Suppose $X_{1},\ldots,X_{n} \sim_{iid}N\left( \mu,\ \sigma^{2} \right)$.</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>Let $X = \left( X_{1},\ldots,X_{n} \right)^{\top}$ be these random</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>variables in vector format. Let $x_{i}$ and $x$ denote the corresponding</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>observed data. Let $\theta = \left( \mu,\sigma^{2} \right)^{\top}$ be</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>the vector of parameters. Let $\Theta$ denote the parameters as a random</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>vector.</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>Then the log-likelihood</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>$\ell \eqdef \ell(X;\theta) \eqdef p\left( X = x \mid \Theta = \theta \right)$</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>is:</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>\ell </span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>&amp;\propto - \frac{n}{2}\log{\sigma^{2}} - \frac{1}{2}\sum_{i = 1}^{n}\frac{\left( x_{i} - \mu \right)^{2}}{\sigma^{2}}<span class="sc">\\</span></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>&amp;= - \frac{n}{2}\log{\sigma^{2}} - \frac{1}{2\sigma^{2}}\sum_{i = 1}^{n}{x_{i}^{2} - 2x_{i}\mu + \mu^{2}}</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a><span class="fu">### MLE of $\mu$</span></span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a>Then:</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a>$$\frac{d\ell}{d\mu} = - \frac{1}{2}\sum_{i = 1}^{n}\frac{- 2\left( x_{i} - \mu \right)}{\sigma^{2}}$$</span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a>$$= \frac{1}{\sigma^{2}}\left\lbrack \left( \sum_{i = 1}^{n}x_{i} \right) - n\mu \right\rbrack$$</span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>If $\frac{d\ell}{d\mu} = 0$, then</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a>$\mu = \overline{x} \eqdef \frac{1}{n}\sum_{i = 1}^{n}x_{i}$.</span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a>$$\frac{d^{2}\ell}{(d\mu)^{2}} = \frac{- n}{\sigma^{2}} &lt; 0$$</span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a>So ${\widehat{\mu}}_{ML} = \overline{x}$.</span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a><span class="fu">### MLE of $\sigma^{2}$</span></span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a><span class="fu">### Reparametrizing the Gaussian distribution</span></span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a>When solving for ${\widehat{\sigma}}_{ML}$, you can treat</span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a>$\sigma^{2}$ as an atomic variable (don’t differentiate with respect to</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a>$\sigma$ or things get messy). In fact, you can replace $\sigma^{2}$</span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a>with $1/\tau$ and differentiate with respect to $\tau$ instead, and the</span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a>process might be even easier.</span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a>$$\frac{d\ell}{d\sigma^{2}} = \frac{d}{d\sigma^{2}}\left( - \frac{n}{2}\log{\sigma^{2}} - \frac{1}{2}\sum_{i = 1}^{n}\frac{\left( x_{i} - \mu \right)^{2}}{\sigma^{2}} \right)\ $$</span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a>$$= - \frac{n}{2}\left( \sigma^{2} \right)^{- 1} + \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2}$$</span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a>If $\frac{d\ell}{d\sigma^{2}} = 0$, then:</span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a>$$\frac{n}{2}\left( \sigma^{2} \right)^{- 1} = \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2}$$</span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a>$$\sigma^{2} = \frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2}$$</span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a>We plug in ${\widehat{\mu}}_{ML} = \overline{x}$ to maximize globally (a</span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a>technique called profiling):</span>
<span id="cb12-102"><a href="#cb12-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-103"><a href="#cb12-103" aria-hidden="true" tabindex="-1"></a>$$\sigma_{ML}^{2} = \frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}$$</span>
<span id="cb12-104"><a href="#cb12-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-105"><a href="#cb12-105" aria-hidden="true" tabindex="-1"></a>Now:</span>
<span id="cb12-106"><a href="#cb12-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-107"><a href="#cb12-107" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-108"><a href="#cb12-108" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-109"><a href="#cb12-109" aria-hidden="true" tabindex="-1"></a>\frac{d^{2}\ell}{\left( d\sigma^{2} \right)^{2}} </span>
<span id="cb12-110"><a href="#cb12-110" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{d}{d\sigma^{2}}\left<span class="sc">\{</span> - \frac{n}{2}\left( \sigma^{2} \right)^{- 1} + \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right<span class="sc">\}\\</span></span>
<span id="cb12-111"><a href="#cb12-111" aria-hidden="true" tabindex="-1"></a>&amp;= \left<span class="sc">\{</span> - \frac{n}{2}\frac{d}{d\sigma^{2}}\left( \sigma^{2} \right)^{- 1} + \frac{1}{2}\frac{d}{d\sigma^{2}}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right<span class="sc">\}\\</span></span>
<span id="cb12-112"><a href="#cb12-112" aria-hidden="true" tabindex="-1"></a>&amp;= \left<span class="sc">\{</span> \frac{n}{2}\left( \sigma^{2} \right)^{- 2} - \left( \sigma^{2} \right)^{- 3}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right<span class="sc">\}\\</span></span>
<span id="cb12-113"><a href="#cb12-113" aria-hidden="true" tabindex="-1"></a>&amp;= \left( \sigma^{2} \right)^{- 2}\left<span class="sc">\{</span> \frac{n}{2} - \left( \sigma^{2} \right)^{- 1}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right<span class="sc">\}</span></span>
<span id="cb12-114"><a href="#cb12-114" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-115"><a href="#cb12-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-116"><a href="#cb12-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-117"><a href="#cb12-117" aria-hidden="true" tabindex="-1"></a>Evaluated at</span>
<span id="cb12-118"><a href="#cb12-118" aria-hidden="true" tabindex="-1"></a>$\mu = \overline{x},\sigma^{2} = \frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}$,</span>
<span id="cb12-119"><a href="#cb12-119" aria-hidden="true" tabindex="-1"></a>we have:</span>
<span id="cb12-120"><a href="#cb12-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-121"><a href="#cb12-121" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-122"><a href="#cb12-122" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-123"><a href="#cb12-123" aria-hidden="true" tabindex="-1"></a>\frac{d^{2}\ell}{\left( d\sigma^{2} \right)^{2}} </span>
<span id="cb12-124"><a href="#cb12-124" aria-hidden="true" tabindex="-1"></a>&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}\left<span class="sc">\{</span> \frac{n}{2} - \left( {\widehat{\sigma}}^{2} \right)^{- 1}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2} \right<span class="sc">\}\\</span></span>
<span id="cb12-125"><a href="#cb12-125" aria-hidden="true" tabindex="-1"></a>&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}\left<span class="sc">\{</span> \frac{n}{2} - \left( {\widehat{\sigma}}^{2} \right)^{- 1}n{\widehat{\sigma}}^{2} \right<span class="sc">\}\\</span></span>
<span id="cb12-126"><a href="#cb12-126" aria-hidden="true" tabindex="-1"></a>&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}\left<span class="sc">\{</span> \frac{n}{2} - n \right<span class="sc">\}\\</span></span>
<span id="cb12-127"><a href="#cb12-127" aria-hidden="true" tabindex="-1"></a>&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}n\left<span class="sc">\{</span> \frac{1}{2} - 1 \right<span class="sc">\}\\</span></span>
<span id="cb12-128"><a href="#cb12-128" aria-hidden="true" tabindex="-1"></a>&amp;= \left( {\widehat{\sigma}}^{2} \right)^{- 2}n\left( - \frac{1}{2} \right) &lt; 0</span>
<span id="cb12-129"><a href="#cb12-129" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-130"><a href="#cb12-130" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-131"><a href="#cb12-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-132"><a href="#cb12-132" aria-hidden="true" tabindex="-1"></a>Finally, we have:</span>
<span id="cb12-133"><a href="#cb12-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-134"><a href="#cb12-134" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-135"><a href="#cb12-135" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-136"><a href="#cb12-136" aria-hidden="true" tabindex="-1"></a>\frac{d^{2}\ell}{d\mu\ d\sigma^{2}} </span>
<span id="cb12-137"><a href="#cb12-137" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{d}{d\mu}\left<span class="sc">\{</span> - \frac{n}{2}\left( \sigma^{2} \right)^{- 1} + \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2} \right<span class="sc">\}\\</span></span>
<span id="cb12-138"><a href="#cb12-138" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\frac{d}{d\mu}\sum_{i = 1}^{n}\left( x_{i} - \mu \right)^{2}<span class="sc">\\</span></span>
<span id="cb12-139"><a href="#cb12-139" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{1}{2}\left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}{- 2(x_{i} - \mu)}<span class="sc">\\</span></span>
<span id="cb12-140"><a href="#cb12-140" aria-hidden="true" tabindex="-1"></a>&amp;= - \left( \sigma^{2} \right)^{- 2}\sum_{i = 1}^{n}{(x_{i} - \mu)}</span>
<span id="cb12-141"><a href="#cb12-141" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-142"><a href="#cb12-142" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-143"><a href="#cb12-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-144"><a href="#cb12-144" aria-hidden="true" tabindex="-1"></a>Evaluated at</span>
<span id="cb12-145"><a href="#cb12-145" aria-hidden="true" tabindex="-1"></a>$\mu = \widehat{\mu} = \overline{x},\sigma^{2} = {\widehat{\sigma}}^{2} = \frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}$,</span>
<span id="cb12-146"><a href="#cb12-146" aria-hidden="true" tabindex="-1"></a>we have:</span>
<span id="cb12-147"><a href="#cb12-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-148"><a href="#cb12-148" aria-hidden="true" tabindex="-1"></a>$$\frac{d^{2}\ell}{d\mu\ d\sigma^{2}} = - \left( {\widehat{\sigma}}^{2} \right)^{- 2}\left( n\overline{x} - n\overline{x} \right) = 0$$</span>
<span id="cb12-149"><a href="#cb12-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-150"><a href="#cb12-150" aria-hidden="true" tabindex="-1"></a><span class="fu">### Covariance matrix of MLEs</span></span>
<span id="cb12-151"><a href="#cb12-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-152"><a href="#cb12-152" aria-hidden="true" tabindex="-1"></a><span class="fu">#### The score function</span></span>
<span id="cb12-153"><a href="#cb12-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-154"><a href="#cb12-154" aria-hidden="true" tabindex="-1"></a>Let $\theta$ be the vector of all parameters; here,</span>
<span id="cb12-155"><a href="#cb12-155" aria-hidden="true" tabindex="-1"></a>$\theta = \left( \mu,\sigma^{2} \right)^{\top}$.</span>
<span id="cb12-156"><a href="#cb12-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-157"><a href="#cb12-157" aria-hidden="true" tabindex="-1"></a>Let</span>
<span id="cb12-158"><a href="#cb12-158" aria-hidden="true" tabindex="-1"></a>$\ell^{'}(x,\theta) \eqdef \frac{d}{d\theta}\ell(x,\theta) = \left( \begin{array}{r}</span>
<span id="cb12-159"><a href="#cb12-159" aria-hidden="true" tabindex="-1"></a>\frac{d}{d\mu}\ell(\theta;x) <span class="sc">\\</span></span>
<span id="cb12-160"><a href="#cb12-160" aria-hidden="true" tabindex="-1"></a>\frac{d}{d\sigma^{2}}\ell(\theta;x)</span>
<span id="cb12-161"><a href="#cb12-161" aria-hidden="true" tabindex="-1"></a>\end{array} \right) = \left( \begin{array}{r}</span>
<span id="cb12-162"><a href="#cb12-162" aria-hidden="true" tabindex="-1"></a>\ell_{\mu}^{'}(\theta;x) <span class="sc">\\</span></span>
<span id="cb12-163"><a href="#cb12-163" aria-hidden="true" tabindex="-1"></a>\ell_{\sigma^{2}}^{'}(\theta;x)</span>
<span id="cb12-164"><a href="#cb12-164" aria-hidden="true" tabindex="-1"></a>\end{array} \right)$.</span>
<span id="cb12-165"><a href="#cb12-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-166"><a href="#cb12-166" aria-hidden="true" tabindex="-1"></a>$\ell^{'}(x,\theta)$ is the function we set equal to 0 and solve</span>
<span id="cb12-167"><a href="#cb12-167" aria-hidden="true" tabindex="-1"></a>to find the MLE:</span>
<span id="cb12-168"><a href="#cb12-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-169"><a href="#cb12-169" aria-hidden="true" tabindex="-1"></a>$${\widehat{\theta}}_{ML} = \left<span class="sc">\{</span> \theta:\ell^{'}(x,\theta) = 0 \right<span class="sc">\}</span>$$</span>
<span id="cb12-170"><a href="#cb12-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-171"><a href="#cb12-171" aria-hidden="true" tabindex="-1"></a>The function $\ell^{'}(x,\theta)$ is so central that it has its</span>
<span id="cb12-172"><a href="#cb12-172" aria-hidden="true" tabindex="-1"></a>own name, the "score" or "gradient" function. Statisticians also often</span>
<span id="cb12-173"><a href="#cb12-173" aria-hidden="true" tabindex="-1"></a>skip writing the arguments $(x,\theta)$, so</span>
<span id="cb12-174"><a href="#cb12-174" aria-hidden="true" tabindex="-1"></a>$\ell^{'} \eqdef \ell^{'}(x,\theta)$.<span class="ot">[^1]</span> Some statisticians</span>
<span id="cb12-175"><a href="#cb12-175" aria-hidden="true" tabindex="-1"></a>use $U$ or $S$ instead of $\ell^{'}$. I prefer $\ell^{'}$.</span>
<span id="cb12-176"><a href="#cb12-176" aria-hidden="true" tabindex="-1"></a>Why use up extra letters?</span>
<span id="cb12-177"><a href="#cb12-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-178"><a href="#cb12-178" aria-hidden="true" tabindex="-1"></a><span class="fu">#### The (Fisher) (expected) information matrix</span></span>
<span id="cb12-179"><a href="#cb12-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-180"><a href="#cb12-180" aria-hidden="true" tabindex="-1"></a>The variance of $\ell^{'}(x,\theta)$,</span>
<span id="cb12-181"><a href="#cb12-181" aria-hidden="true" tabindex="-1"></a>${Cov}\left<span class="sc">\{</span> \ell^{'}(x,\theta) \right<span class="sc">\}</span>$, is also very</span>
<span id="cb12-182"><a href="#cb12-182" aria-hidden="true" tabindex="-1"></a>important; we call it the "expected information matrix", "Fisher</span>
<span id="cb12-183"><a href="#cb12-183" aria-hidden="true" tabindex="-1"></a>information matrix", or just "information matrix", and we represent it</span>
<span id="cb12-184"><a href="#cb12-184" aria-hidden="true" tabindex="-1"></a>using the symbol $\mathfrak{I}$ (<span class="in">`\frakturI`</span> in Unicode, <span class="in">`\mathfrak{I}`</span> in LaTeX).</span>
<span id="cb12-185"><a href="#cb12-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-186"><a href="#cb12-186" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Review of variances and covariances</span></span>
<span id="cb12-187"><a href="#cb12-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-188"><a href="#cb12-188" aria-hidden="true" tabindex="-1"></a><span class="fu">###### Variances and covariances of one-dimensional random variables</span></span>
<span id="cb12-189"><a href="#cb12-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-190"><a href="#cb12-190" aria-hidden="true" tabindex="-1"></a>For a one-dimensional random variables $X$,</span>
<span id="cb12-191"><a href="#cb12-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-192"><a href="#cb12-192" aria-hidden="true" tabindex="-1"></a>$${Var}(X) \eqdef Ε\left\lbrack \left( X - Ε\lbrack X\rbrack \right)^{2} \right\rbrack = Ε\left\lbrack X^{2} \right\rbrack - \left( Ε\lbrack X\rbrack \right)^{2}$$</span>
<span id="cb12-193"><a href="#cb12-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-194"><a href="#cb12-194" aria-hidden="true" tabindex="-1"></a>For any two-dimensional random variables, $X,Y$:</span>
<span id="cb12-195"><a href="#cb12-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-196"><a href="#cb12-196" aria-hidden="true" tabindex="-1"></a>$${Cov}(X,Y) = E\left\lbrack (X - ΕX)(Y - ΕY) \right\rbrack = Ε\lbrack XY\rbrack - E\lbrack X\rbrack E\lbrack Y\rbrack$$</span>
<span id="cb12-197"><a href="#cb12-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-198"><a href="#cb12-198" aria-hidden="true" tabindex="-1"></a>Therefore,</span>
<span id="cb12-199"><a href="#cb12-199" aria-hidden="true" tabindex="-1"></a>${Var}{(X)} = {Cov}(X,X) = Ε\lbrack XX\rbrack - E\lbrack X\rbrack E\lbrack X\rbrack = Ε\left\lbrack X^{2} \right\rbrack - \left( E\lbrack X\rbrack \right)^{2}$</span>
<span id="cb12-200"><a href="#cb12-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-201"><a href="#cb12-201" aria-hidden="true" tabindex="-1"></a>$$\mathfrak{I \eqdef I(}\theta) \eqdef {Cov}\left( \ell^{'}|\theta \right) = Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack - Ε\left\lbrack \ell^{'} \right\rbrack\ Ε\left\lbrack \ell^{'} \right\rbrack^{\top}$$</span>
<span id="cb12-202"><a href="#cb12-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-203"><a href="#cb12-203" aria-hidden="true" tabindex="-1"></a>Sometimes we write ${Cov}{(X)} \eqdef {Cov}(X,X) = {Var}(X)$.</span>
<span id="cb12-204"><a href="#cb12-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-205"><a href="#cb12-205" aria-hidden="true" tabindex="-1"></a><span class="fu">###### Variances and covariances of $p \times 1$ random vectors</span></span>
<span id="cb12-206"><a href="#cb12-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-207"><a href="#cb12-207" aria-hidden="true" tabindex="-1"></a>Now, for a $p \times 1$ dimensional random vector $X$,</span>
<span id="cb12-208"><a href="#cb12-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-209"><a href="#cb12-209" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-210"><a href="#cb12-210" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-211"><a href="#cb12-211" aria-hidden="true" tabindex="-1"></a>\text{Var}(X) </span>
<span id="cb12-212"><a href="#cb12-212" aria-hidden="true" tabindex="-1"></a>&amp;\eqdef \text{Cov}(X)<span class="sc">\\</span></span>
<span id="cb12-213"><a href="#cb12-213" aria-hidden="true" tabindex="-1"></a>&amp;\eqdef E\left\lbrack \left( X - E\lbrack X\rbrack \right)^{\top}\left( X - E\lbrack X\rbrack \right) \right\rbrack<span class="sc">\\</span></span>
<span id="cb12-214"><a href="#cb12-214" aria-hidden="true" tabindex="-1"></a>&amp;= E\left\lbrack \left( X^{\top} - E\lbrack X\rbrack^{\top} \right)\left( X - E\lbrack X\rbrack \right) \right\rbrack<span class="sc">\\</span></span>
<span id="cb12-215"><a href="#cb12-215" aria-hidden="true" tabindex="-1"></a>&amp;= E\left\lbrack X^{\top}X - E\lbrack X\rbrack^{\top}X - X^{\top}E\lbrack X\rbrack + E\lbrack X\rbrack^{\top}E\lbrack X\rbrack \right\rbrack<span class="sc">\\</span></span>
<span id="cb12-216"><a href="#cb12-216" aria-hidden="true" tabindex="-1"></a>&amp;= E\left\lbrack X^{\top}X \right\rbrack - E\lbrack X\rbrack^{\top}E\lbrack X\rbrack - {E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack + E\lbrack X\rbrack^{\top}E\lbrack X\rbrack<span class="sc">\\</span></span>
<span id="cb12-217"><a href="#cb12-217" aria-hidden="true" tabindex="-1"></a>&amp;= E\left\lbrack X^{\top}X \right\rbrack - 2{E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack + E\lbrack X\rbrack^{\top}E\lbrack X\rbrack<span class="sc">\\</span></span>
<span id="cb12-218"><a href="#cb12-218" aria-hidden="true" tabindex="-1"></a>&amp;= E\left\lbrack X^{\top}X \right\rbrack - {E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack</span>
<span id="cb12-219"><a href="#cb12-219" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-220"><a href="#cb12-220" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-221"><a href="#cb12-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-222"><a href="#cb12-222" aria-hidden="true" tabindex="-1"></a>The elements of $\mathfrak{I}$ are:</span>
<span id="cb12-223"><a href="#cb12-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-224"><a href="#cb12-224" aria-hidden="true" tabindex="-1"></a>$$\left<span class="sc">\{</span> \mathfrak{I}_{ij} \eqdef {Cov}\left( {\ell^{'}}_{i},{\ell^{'}}_{j} \right) = Ε\left\lbrack \ell_{i}^{'}\ell_{j}^{'} \right\rbrack - Ε\left\lbrack {\ell^{'}}_{i} \right\rbrack Ε\left\lbrack {\ell^{'}}_{j} \right\rbrack \right<span class="sc">\}</span>$$</span>
<span id="cb12-225"><a href="#cb12-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-226"><a href="#cb12-226" aria-hidden="true" tabindex="-1"></a>In our motivating example, $i,j \in \left<span class="sc">\{</span> \mu,\sigma^{2} \right<span class="sc">\}</span>$. Here, </span>
<span id="cb12-227"><a href="#cb12-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-228"><a href="#cb12-228" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-229"><a href="#cb12-229" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-230"><a href="#cb12-230" aria-hidden="true" tabindex="-1"></a>Ε<span class="co">[</span><span class="ot">\ell'</span><span class="co">]</span></span>
<span id="cb12-231"><a href="#cb12-231" aria-hidden="true" tabindex="-1"></a>&amp;\eqdef \int_{x \in \mathfrak R(x)}{\ell'(x,\theta) p(X = x | \theta)dx}<span class="sc">\\</span></span>
<span id="cb12-232"><a href="#cb12-232" aria-hidden="true" tabindex="-1"></a>&amp;= \int_{x\in \mathfrak R(x)}{\left( \frac{d}{d\theta}\log{p\left( X = x \mid \theta \right)} \right)\ p\left( X = x \mid \theta \right)\ dx}<span class="sc">\\</span></span>
<span id="cb12-233"><a href="#cb12-233" aria-hidden="true" tabindex="-1"></a>&amp;= \int_{x \in \mathfrak R(x)}{\frac{\frac{d}{d\theta}p\left( X = x \mid \theta \right)}{p\left( X = x \mid \theta \right)}p\left( X = x \mid \theta \right)\ dx</span>
<span id="cb12-234"><a href="#cb12-234" aria-hidden="true" tabindex="-1"></a>}<span class="sc">\\</span></span>
<span id="cb12-235"><a href="#cb12-235" aria-hidden="true" tabindex="-1"></a>&amp;= \int_{x \in \mathfrak R(x)}{\frac{d}{d\theta}p\left( X = x \mid \theta \right)\ dx}</span>
<span id="cb12-236"><a href="#cb12-236" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-237"><a href="#cb12-237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-238"><a href="#cb12-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-239"><a href="#cb12-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-240"><a href="#cb12-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-241"><a href="#cb12-241" aria-hidden="true" tabindex="-1"></a>And similarly</span>
<span id="cb12-242"><a href="#cb12-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-243"><a href="#cb12-243" aria-hidden="true" tabindex="-1"></a>$$Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack \eqdef \int_{x \in R(x)}^{}{\ell^{'}(x,\theta)\ell^{'}(x,\theta)^{\top}\ p\left( X = x \mid \theta \right)\ dx}$$</span>
<span id="cb12-244"><a href="#cb12-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-245"><a href="#cb12-245" aria-hidden="true" tabindex="-1"></a>Note that $Ε\left\lbrack \ell^{'} \right\rbrack$ and</span>
<span id="cb12-246"><a href="#cb12-246" aria-hidden="true" tabindex="-1"></a>$Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack$</span>
<span id="cb12-247"><a href="#cb12-247" aria-hidden="true" tabindex="-1"></a>are functions of $\theta$ but not of $x$; the expectation operator</span>
<span id="cb12-248"><a href="#cb12-248" aria-hidden="true" tabindex="-1"></a>removed $x$.</span>
<span id="cb12-249"><a href="#cb12-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-250"><a href="#cb12-250" aria-hidden="true" tabindex="-1"></a>Also note that for most of the distributions you are familiar with</span>
<span id="cb12-251"><a href="#cb12-251" aria-hidden="true" tabindex="-1"></a>(including Gaussian, binomial, Poisson, exponential),</span>
<span id="cb12-252"><a href="#cb12-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-253"><a href="#cb12-253" aria-hidden="true" tabindex="-1"></a>$$Ε\left\lbrack \ell^{'} \right\rbrack = 0$$</span>
<span id="cb12-254"><a href="#cb12-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-255"><a href="#cb12-255" aria-hidden="true" tabindex="-1"></a>So</span>
<span id="cb12-256"><a href="#cb12-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-257"><a href="#cb12-257" aria-hidden="true" tabindex="-1"></a>$$\mathfrak{I =}Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack$$</span>
<span id="cb12-258"><a href="#cb12-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-259"><a href="#cb12-259" aria-hidden="true" tabindex="-1"></a>Moreover, for those distributions (called the "exponential family"), we</span>
<span id="cb12-260"><a href="#cb12-260" aria-hidden="true" tabindex="-1"></a>have:</span>
<span id="cb12-261"><a href="#cb12-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-262"><a href="#cb12-262" aria-hidden="true" tabindex="-1"></a>$$\mathfrak{I = -}Ε\left\lbrack \ell^{''} \right\rbrack = Ε\left\lbrack - \ell^{''} \right\rbrack$$</span>
<span id="cb12-263"><a href="#cb12-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-264"><a href="#cb12-264" aria-hidden="true" tabindex="-1"></a>(see Dobson and Barnett 4e, §3.17), where</span>
<span id="cb12-265"><a href="#cb12-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-266"><a href="#cb12-266" aria-hidden="true" tabindex="-1"></a>$$\ell^{''} \eqdef \frac{d}{d\theta}\ell^{'(x,\theta)^{\top}} = \frac{d}{d\theta}\frac{d}{d\theta^{\top}}\ell(x,\theta)$$</span>
<span id="cb12-267"><a href="#cb12-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-268"><a href="#cb12-268" aria-hidden="true" tabindex="-1"></a>is the $p \times p$ matrix whose elements are:</span>
<span id="cb12-269"><a href="#cb12-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-270"><a href="#cb12-270" aria-hidden="true" tabindex="-1"></a>$$\ell_{ij}'' \eqdef \frac{d}{d\theta_{i}}\frac{d}{d\theta_{j}}\log{ p\left( X = x \mid \theta \right)}$$</span>
<span id="cb12-271"><a href="#cb12-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-272"><a href="#cb12-272" aria-hidden="true" tabindex="-1"></a>$\ell''$ could be called the "Hessian" of the log-likelihood</span>
<span id="cb12-273"><a href="#cb12-273" aria-hidden="true" tabindex="-1"></a>function.</span>
<span id="cb12-274"><a href="#cb12-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-275"><a href="#cb12-275" aria-hidden="true" tabindex="-1"></a>Sometimes, we use $I(\theta;x) \eqdef - \ell^{''}$ (note the</span>
<span id="cb12-276"><a href="#cb12-276" aria-hidden="true" tabindex="-1"></a>standard-font "I" here). $I(\theta;x)$ is the observed information, precision, or concentration</span>
<span id="cb12-277"><a href="#cb12-277" aria-hidden="true" tabindex="-1"></a>matrix (Negative Hessian).</span>
<span id="cb12-278"><a href="#cb12-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-279"><a href="#cb12-279" aria-hidden="true" tabindex="-1"></a>:::{.callout-important}</span>
<span id="cb12-280"><a href="#cb12-280" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key point</span></span>
<span id="cb12-281"><a href="#cb12-281" aria-hidden="true" tabindex="-1"></a> The asymptotics of MLEs gives us</span>
<span id="cb12-282"><a href="#cb12-282" aria-hidden="true" tabindex="-1"></a>${\widehat{\theta}}_{ML} \sim N\left( \theta,\mathfrak{I}^{- 1}(\theta) \right)$,</span>
<span id="cb12-283"><a href="#cb12-283" aria-hidden="true" tabindex="-1"></a>approximately, for large sample sizes.</span>
<span id="cb12-284"><a href="#cb12-284" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-285"><a href="#cb12-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-286"><a href="#cb12-286" aria-hidden="true" tabindex="-1"></a>We can estimate $\mathfrak{I}^{- 1}(\theta)$ by working out</span>
<span id="cb12-287"><a href="#cb12-287" aria-hidden="true" tabindex="-1"></a>$- Ε\left\lbrack \ell^{''} \right\rbrack$ or</span>
<span id="cb12-288"><a href="#cb12-288" aria-hidden="true" tabindex="-1"></a>$Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack$</span>
<span id="cb12-289"><a href="#cb12-289" aria-hidden="true" tabindex="-1"></a>and plugging in ${\widehat{\theta}}_{ML}$, but sometimes we instead use</span>
<span id="cb12-290"><a href="#cb12-290" aria-hidden="true" tabindex="-1"></a>$I\left( {\widehat{\theta}}_{ML};x \right)$ for convenience; there are</span>
<span id="cb12-291"><a href="#cb12-291" aria-hidden="true" tabindex="-1"></a>some cases where it’s provably better according to some criteria (Efron</span>
<span id="cb12-292"><a href="#cb12-292" aria-hidden="true" tabindex="-1"></a>&amp; Hinkley 1978).</span>
<span id="cb12-293"><a href="#cb12-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-294"><a href="#cb12-294" aria-hidden="true" tabindex="-1"></a>Note that later, when we are trying to find MLEs for likelihoods that we</span>
<span id="cb12-295"><a href="#cb12-295" aria-hidden="true" tabindex="-1"></a>can’t easily differentiate, we will "hill-climb" using the</span>
<span id="cb12-296"><a href="#cb12-296" aria-hidden="true" tabindex="-1"></a>Newton-Raphson algorithm:</span>
<span id="cb12-297"><a href="#cb12-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-298"><a href="#cb12-298" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-299"><a href="#cb12-299" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-300"><a href="#cb12-300" aria-hidden="true" tabindex="-1"></a>\widehat{\theta} </span>
<span id="cb12-301"><a href="#cb12-301" aria-hidden="true" tabindex="-1"></a>&amp;\leftarrow \widehat{\theta} + \left\lbrack I\left( \widehat{\theta},y \right) \right\rbrack^{- 1}\ell^{'}\left( y,\widehat{\theta} \right)<span class="sc">\\</span></span>
<span id="cb12-302"><a href="#cb12-302" aria-hidden="true" tabindex="-1"></a>&amp;= \widehat{\theta} - \left\lbrack \ell^{''}\left( y,\widehat{\theta} \right) \right\rbrack^{- 1}\ell^{'}\left( y,\widehat{\theta} \right)</span>
<span id="cb12-303"><a href="#cb12-303" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-304"><a href="#cb12-304" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-305"><a href="#cb12-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-306"><a href="#cb12-306" aria-hidden="true" tabindex="-1"></a>Here, for computational simplicity, we will sometimes use</span>
<span id="cb12-307"><a href="#cb12-307" aria-hidden="true" tabindex="-1"></a>$\mathfrak{I}^{- 1}(\theta)$ in place of</span>
<span id="cb12-308"><a href="#cb12-308" aria-hidden="true" tabindex="-1"></a>$I\left( \widehat{\theta},y \right)$; doing so is called "Fisher</span>
<span id="cb12-309"><a href="#cb12-309" aria-hidden="true" tabindex="-1"></a>scoring" or the "method of scoring". Note that this is the opposite of</span>
<span id="cb12-310"><a href="#cb12-310" aria-hidden="true" tabindex="-1"></a>the substitution that we are making for estimating the variance of the</span>
<span id="cb12-311"><a href="#cb12-311" aria-hidden="true" tabindex="-1"></a>MLE; this time we should technically use the observed information but we</span>
<span id="cb12-312"><a href="#cb12-312" aria-hidden="true" tabindex="-1"></a>use the expected information instead.</span>
<span id="cb12-313"><a href="#cb12-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-314"><a href="#cb12-314" aria-hidden="true" tabindex="-1"></a>There’s also an "empirical information matrix" (see McLachlan and</span>
<span id="cb12-315"><a href="#cb12-315" aria-hidden="true" tabindex="-1"></a>Krishnan 2007).</span>
<span id="cb12-316"><a href="#cb12-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-317"><a href="#cb12-317" aria-hidden="true" tabindex="-1"></a>$$I_{e}(\theta,y) = \sum_{i = 1}^{n}{\ell_{i}^{'}\ {\ell_{i}^{'}}^{\top}} - \frac{1}{n}\ell^{'}{\ell^{'}}^{\top}$$</span>
<span id="cb12-318"><a href="#cb12-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-319"><a href="#cb12-319" aria-hidden="true" tabindex="-1"></a>where $\ell_{i}$ is the log-likelihood of the ith observation.</span>
<span id="cb12-320"><a href="#cb12-320" aria-hidden="true" tabindex="-1"></a>Note that $\ell^{'} = \sum_{i = 1}^{n}\ell_{i}^{'}$.</span>
<span id="cb12-321"><a href="#cb12-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-322"><a href="#cb12-322" aria-hidden="true" tabindex="-1"></a>$\frac{1}{n}I_{e}(\theta,y)$ is the sample equivalent of</span>
<span id="cb12-323"><a href="#cb12-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-324"><a href="#cb12-324" aria-hidden="true" tabindex="-1"></a>$$\mathfrak{I \eqdef I(}\theta) \eqdef {Cov}\left( \ell^{'}|\theta \right) = Ε\left\lbrack \ell^{'}{\ell^{'}}^{\top} \right\rbrack - Ε\left\lbrack \ell^{'} \right\rbrack\ Ε\left\lbrack \ell^{'} \right\rbrack^{\top}$$</span>
<span id="cb12-325"><a href="#cb12-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-326"><a href="#cb12-326" aria-hidden="true" tabindex="-1"></a>$$\left<span class="sc">\{</span> \mathfrak{I}_{jk} \eqdef {Cov}\left( {\ell^{'}}_{j},{\ell^{'}}_{k} \right) = Ε\left\lbrack \ell_{j}^{'}\ell_{k}^{'} \right\rbrack - Ε\left\lbrack {\ell^{'}}_{j} \right\rbrack Ε\left\lbrack {\ell^{'}}_{k} \right\rbrack \right<span class="sc">\}</span>$$</span>
<span id="cb12-327"><a href="#cb12-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-328"><a href="#cb12-328" aria-hidden="true" tabindex="-1"></a>$I_{e}(\theta,y)$ is sometimes computationally easier to compute for</span>
<span id="cb12-329"><a href="#cb12-329" aria-hidden="true" tabindex="-1"></a>Newton-Raphson-type maximization algorithms.</span>
<span id="cb12-330"><a href="#cb12-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-331"><a href="#cb12-331" aria-hidden="true" tabindex="-1"></a>Back to our Gaussian example:</span>
<span id="cb12-332"><a href="#cb12-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-333"><a href="#cb12-333" aria-hidden="true" tabindex="-1"></a>$$I = \begin{bmatrix}</span>
<span id="cb12-334"><a href="#cb12-334" aria-hidden="true" tabindex="-1"></a>\frac{n}{\sigma^{2}} &amp; 0 <span class="sc">\\</span></span>
<span id="cb12-335"><a href="#cb12-335" aria-hidden="true" tabindex="-1"></a>0 &amp; \left( {\widehat{\sigma}}^{2} \right)^{- 2}n\left( - \frac{1}{2} \right)</span>
<span id="cb12-336"><a href="#cb12-336" aria-hidden="true" tabindex="-1"></a>\end{bmatrix} = \begin{bmatrix}</span>
<span id="cb12-337"><a href="#cb12-337" aria-hidden="true" tabindex="-1"></a>a &amp; 0 <span class="sc">\\</span></span>
<span id="cb12-338"><a href="#cb12-338" aria-hidden="true" tabindex="-1"></a>0 &amp; d</span>
<span id="cb12-339"><a href="#cb12-339" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}$$</span>
<span id="cb12-340"><a href="#cb12-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-341"><a href="#cb12-341" aria-hidden="true" tabindex="-1"></a>So:</span>
<span id="cb12-342"><a href="#cb12-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-343"><a href="#cb12-343" aria-hidden="true" tabindex="-1"></a>$$I^{- 1} = \frac{1}{ad}\begin{bmatrix}</span>
<span id="cb12-344"><a href="#cb12-344" aria-hidden="true" tabindex="-1"></a>d &amp; 0 <span class="sc">\\</span></span>
<span id="cb12-345"><a href="#cb12-345" aria-hidden="true" tabindex="-1"></a>0 &amp; a</span>
<span id="cb12-346"><a href="#cb12-346" aria-hidden="true" tabindex="-1"></a>\end{bmatrix} = \begin{bmatrix}</span>
<span id="cb12-347"><a href="#cb12-347" aria-hidden="true" tabindex="-1"></a>\frac{1}{a} &amp; 0 <span class="sc">\\</span></span>
<span id="cb12-348"><a href="#cb12-348" aria-hidden="true" tabindex="-1"></a>0 &amp; \frac{1}{d}</span>
<span id="cb12-349"><a href="#cb12-349" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}$$</span>
<span id="cb12-350"><a href="#cb12-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-351"><a href="#cb12-351" aria-hidden="true" tabindex="-1"></a>$$I^{- 1} = \begin{bmatrix}</span>
<span id="cb12-352"><a href="#cb12-352" aria-hidden="true" tabindex="-1"></a>\frac{{\widehat{\sigma}}^{2}}{n} &amp; 0 <span class="sc">\\</span></span>
<span id="cb12-353"><a href="#cb12-353" aria-hidden="true" tabindex="-1"></a>0 &amp; \frac{{2\left( {\widehat{\sigma}}^{2} \right)}^{2}}{n}</span>
<span id="cb12-354"><a href="#cb12-354" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}$$</span>
<span id="cb12-355"><a href="#cb12-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-356"><a href="#cb12-356" aria-hidden="true" tabindex="-1"></a>See @CaseBerg01 p322, example 7.2.12.</span>
<span id="cb12-357"><a href="#cb12-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-358"><a href="#cb12-358" aria-hidden="true" tabindex="-1"></a>To prove it’s a maximum, need:</span>
<span id="cb12-359"><a href="#cb12-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-360"><a href="#cb12-360" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\ell^{'} = 0$</span>
<span id="cb12-361"><a href="#cb12-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-362"><a href="#cb12-362" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>At least one diagonal element of $\mathfrak{l''}$ is negative.</span>
<span id="cb12-363"><a href="#cb12-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-364"><a href="#cb12-364" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Determinant of $\mathfrak{l''}$ is positive.</span>
<span id="cb12-365"><a href="#cb12-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-366"><a href="#cb12-366" aria-hidden="true" tabindex="-1"></a><span class="fu">### Confidence intervals for MLEs</span></span>
<span id="cb12-367"><a href="#cb12-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-368"><a href="#cb12-368" aria-hidden="true" tabindex="-1"></a><span class="fu">### p-values and hypothesis tests for MLEs</span></span>
<span id="cb12-369"><a href="#cb12-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-370"><a href="#cb12-370" aria-hidden="true" tabindex="-1"></a><span class="fu">### Likelihood ratio tests for MLEs</span></span>
<span id="cb12-371"><a href="#cb12-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-372"><a href="#cb12-372" aria-hidden="true" tabindex="-1"></a><span class="sc">\[</span>We haven’t gone over this yet<span class="sc">\]</span></span>
<span id="cb12-373"><a href="#cb12-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-374"><a href="#cb12-374" aria-hidden="true" tabindex="-1"></a>log(likelihood ratio) tests <span class="co">[</span><span class="ot">c.f. @dobson2018introduction §5.7</span><span class="co">]</span>:</span>
<span id="cb12-375"><a href="#cb12-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-376"><a href="#cb12-376" aria-hidden="true" tabindex="-1"></a>$$2\left( \mathfrak{l -}\ell_{0} \right) \sim \chi^{2}(p - q)$$</span>
<span id="cb12-377"><a href="#cb12-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-378"><a href="#cb12-378" aria-hidden="true" tabindex="-1"></a>See also https://online.stat.psu.edu/stat504/book/export/html/657</span>
<span id="cb12-379"><a href="#cb12-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-380"><a href="#cb12-380" aria-hidden="true" tabindex="-1"></a><span class="fu">### Prediction intervals for MLEs</span></span>
<span id="cb12-381"><a href="#cb12-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-382"><a href="#cb12-382" aria-hidden="true" tabindex="-1"></a>$$\overline{X} \in \left\lbrack \widehat{\mu} \pm z_{1 - \alpha\text{/}2}\frac{\sigma}{m} \right\rbrack$$</span>
<span id="cb12-383"><a href="#cb12-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-384"><a href="#cb12-384" aria-hidden="true" tabindex="-1"></a>Where $m$ is the sample size of the new data to be predicted (typically</span>
<span id="cb12-385"><a href="#cb12-385" aria-hidden="true" tabindex="-1"></a>1, except for binary outcomes, where it needs to be bigger for</span>
<span id="cb12-386"><a href="#cb12-386" aria-hidden="true" tabindex="-1"></a>prediction intervals to make sense)</span>
<span id="cb12-387"><a href="#cb12-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-388"><a href="#cb12-388" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>I might sometimes switch the order of $x,$ $\theta$; this is</span>
<span id="cb12-389"><a href="#cb12-389" aria-hidden="true" tabindex="-1"></a>    unintentional and not meaningful.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
<li class="nav-item">
 Copyright 2023, Douglas Ezra Morrison
  </li>  
</ul>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/d-morrison/rme/edit/main/intro-MLEs.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/d-morrison/rme/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>


</body></html>